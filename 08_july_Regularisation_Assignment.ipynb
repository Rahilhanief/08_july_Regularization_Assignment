{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824985b8-43db-478e-b612-f5dce9d09cb1",
   "metadata": {},
   "source": [
    "Part 1: Understanding Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01d0cd23-1ccb-429a-afa2-27f83bb6ff01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRegularization in deep learning is a technique used to prevent overfitting and improve the generalization \\nof neural networks. It involves adding a regularization term to the loss function, which penalizes large \\nweights or complex model architectures.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q  No. 1 :\n",
    "\"\"\"\n",
    "Regularization in deep learning is a technique used to prevent overfitting and improve the generalization \n",
    "of neural networks. It involves adding a regularization term to the loss function, which penalizes large \n",
    "weights or complex model architectures.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c4ebcae-954e-4d35-8b00-45b0f28f0a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRegularization will help select a midpoint between the first scenario of high bias and the later scenario of highvariance\\nThis ideal goal of generalization in terms of bias and variance is a low bias and a low variance which is near impossible\\nor difficult to achieve.Hence, the need of the trade-off.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q NO. 2 :\n",
    "\"\"\"\n",
    "Regularization will help select a midpoint between the first scenario of high bias and the later scenario of highvariance\n",
    "This ideal goal of generalization in terms of bias and variance is a low bias and a low variance which is near impossible\n",
    "or difficult to achieve.Hence, the need of the trade-off.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2ab5dc0-fad0-4f27-ba51-27916c83af41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nL1 Regularization, also called a lasso regression, adds the “absolute value of magnitude” of the coefficient as a \\npenalty term to the loss function. L2 Regularization, also called a ridge regression, adds the “squared magnitude” \\nof the coefficient as the penalty term to the loss function.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 3 :\n",
    "\"\"\"\n",
    "L1 Regularization, also called a lasso regression, adds the “absolute value of magnitude” of the coefficient as a \n",
    "penalty term to the loss function. L2 Regularization, also called a ridge regression, adds the “squared magnitude” \n",
    "of the coefficient as the penalty term to the loss function.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaf860e9-3cb8-49c4-9e6e-8ae6692fab11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRegularization in machine learning is the process of regularizing the parameters that constrain, regularizes, or \\nshrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or \\nflexible model, avoiding the risk of Overfitting.\\nRegularization is a set of techniques that can prevent overfitting in neural networks and thus improve the accuracy of \\na Deep Learning model when facing completely new data from the problem domain.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 4 :\n",
    "\"\"\"\n",
    "Regularization in machine learning is the process of regularizing the parameters that constrain, regularizes, or \n",
    "shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or \n",
    "flexible model, avoiding the risk of Overfitting.\n",
    "Regularization is a set of techniques that can prevent overfitting in neural networks and thus improve the accuracy of \n",
    "a Deep Learning model when facing completely new data from the problem domain.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ea8ffd-0d7a-40e8-807b-05822ec11627",
   "metadata": {},
   "source": [
    "Part 2: Regularization Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3272007-4ff9-4312-9602-392ea4eb2d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDropout Regularization\\nWhen you have training data, if you try to train your model too much, it might overfit, and when you get the actual \\ntest data for making predictions, it will not probably perform well. Dropout regularization is one technique used to \\ntackle overfitting problems in deep learning.\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 5 :\n",
    "\"\"\"\n",
    "Dropout Regularization\n",
    "When you have training data, if you try to train your model too much, it might overfit, and when you get the actual \n",
    "test data for making predictions, it will not probably perform well. Dropout regularization is one technique used to \n",
    "tackle overfitting problems in deep learning.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "725cb377-4b8f-4dcd-b8e8-8b5ad77ee225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEarly Stopping is a regularization technique for deep neural networks that stops training when parameter updates \\nno longer begin to yield improves on a validation set.\\n\\nIn machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner\\nwith an iterative method, such as gradient descent.\\nSuch methods update the learner so as to make it better fit the training data with each iteration.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 6 :\n",
    "\"\"\"\n",
    "Early Stopping is a regularization technique for deep neural networks that stops training when parameter updates \n",
    "no longer begin to yield improves on a validation set.\n",
    "\n",
    "In machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner\n",
    "with an iterative method, such as gradient descent.\n",
    "Such methods update the learner so as to make it better fit the training data with each iteration.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4686d3ea-9264-469d-9b26-aba0fd0b075f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBatch Norm is a normalization technique done between the layers of a Neural Network instead of in the raw data.\\nIt is done along mini-batches instead of the full data set. It serves to speed up training and use higher\\nlearning rates, making learning easier. the standard deviation of the neurons' output.\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Q No. 7 :\n",
    "\"\"\"\n",
    "Batch Norm is a normalization technique done between the layers of a Neural Network instead of in the raw data.\n",
    "It is done along mini-batches instead of the full data set. It serves to speed up training and use higher\n",
    "learning rates, making learning easier. the standard deviation of the neurons' output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74fb5e-2b85-4685-a22a-367cafe3c0a5",
   "metadata": {},
   "source": [
    "Part 3: Applying Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b547146-18c7-4901-98c5-92ab6d0b04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q No. 8 :\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcf9077-6fdc-43ce-bddc-01e4540fb14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.56.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a502d32b-b5a3-45d9-905f-40c9e6f22b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7bad7-f9fc-40e5-afb5-5c02286ded6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-08 10:56:21.068676: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-08 10:56:21.609486: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-08 10:56:21.612494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-08 10:56:23.452768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "160/160 [==============================] - 13s 75ms/step - loss: 2.0227 - accuracy: 0.2686 - val_loss: 1.6611 - val_accuracy: 0.4240\n",
      "Epoch 2/10\n",
      " 35/160 [=====>........................] - ETA: 10s - loss: 1.6053 - accuracy: 0.4149"
     ]
    }
   ],
   "source": [
    "## Q No. 9 :\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "# Model configuration\n",
    "img_width, img_height         = 32, 32\n",
    "batch_size                    = 250\n",
    "no_epochs                     = 10\n",
    "no_classes                    = 10\n",
    "validation_split              = 0.2\n",
    "verbosity                     = 1\n",
    "max_norm_value                = 2.0\n",
    "\n",
    "# Load CIFAR10 dataset\n",
    "(input_train, target_train), (input_test, target_test) = cifar10.load_data()\n",
    "\n",
    "# Reshape data based on channels first / channels last strategy.\n",
    "# This is dependent on whether you use TF, Theano or CNTK as backend.\n",
    "# Source: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_train = input_train.reshape(input_train.shape[0],3, img_width, img_height)\n",
    "    input_test = input_test.reshape(input_test.shape[0], 3, img_width, img_height)\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 3)\n",
    "    input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 3)\n",
    "    input_shape = (img_width  , img_height, 3)\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Normalize data\n",
    "input_train = input_train / 255\n",
    "input_test = input_test / 255\n",
    "\n",
    "# Convert target vectors to categorical targets\n",
    "target_train = keras.utils.to_categorical(target_train, no_classes)\n",
    "target_test = keras.utils.to_categorical(target_test, no_classes)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), kernel_constraint=max_norm(max_norm_value), activation='relu', input_shape=input_shape, kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu', kernel_constraint=max_norm(max_norm_value), kernel_initializer='he_uniform'))\n",
    "model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit data to model\n",
    "model.fit(input_train, target_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=no_epochs,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split\n",
    ")\n",
    "\n",
    "# Generate generalization metrics\n",
    "score = model.evaluate(input_test, target_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
